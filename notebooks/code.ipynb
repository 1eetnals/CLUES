{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re \n",
    "import json\n",
    "import openai  \n",
    "import asyncio\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import notebook\n",
    "from tqdm.notebook import tqdm\n",
    "from openai import AsyncOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter \n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from rank_bm25 import BM25Okapi   # lexical search; sparse vector filter\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, confusion_matrix, cohen_kappa_score \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OpenAI API key\n",
    "os.environ['OPENAI_API_KEY']='your_api_key_here'  \n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('Data.xlsx')\n",
    "\n",
    "\n",
    "# # Load data\n",
    "# def load_data(filepath):\n",
    "#     return pd.read_excel(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doi = '급성 뇌졸중'   # Disease of Interest\n",
    "\n",
    "# Define the imaging report types and the corresponding column names for storing results.\n",
    "imaging_types = [\n",
    "    ('MRI', 'MRI'),\n",
    "    ('CT', 'CT'),\n",
    "    ('ANG', 'ANG')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove special characters\n",
    "def remove_special_characters(text):\n",
    "    # Remove all characters except alphanumeric characters and whitespace\n",
    "    return re.sub(r'[^a-zA-Z0-9가-힣\\s]', '', str(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to remove special characters from each report column\n",
    "for col, _ in imaging_types:\n",
    "    df[col] = df[col].apply(remove_special_characters)\n",
    "\n",
    "# Print the first few rows of the dataframe to verify the results\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1 : Zero-Shot + Ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot prompt for Stage 1\n",
    "zeroshot_prompt = \"\"\"\n",
    "다음과 같은 {imaging_report}이/가 Input으로 주어졌을 때, \n",
    "차트 리뷰를 하여 환자가 {disease} 환자인지 판단합니다.\n",
    "\n",
    "<판단> 에서 {disease} 환자일 확률을 0과 1사이의 값으로 나타냅니다.\n",
    "논리적으로 생각하고 <결정 근거>에서 자신의 결정에 대한 추론을 제공합니다.\n",
    "\n",
    "Output에는 다음 형식을 사용합니다.\n",
    "<판단> : (0과 1사이의 값만 해당) \n",
    "<결정근거> : \n",
    "\n",
    "Input : {input_text}\n",
    "Output :\n",
    "\"\"\"\n",
    "\n",
    "# Few-shot propmt for Stage 2\n",
    "fewshot_prompt = \"\"\"\n",
    "다음과 같은 {imaging_report}이/가 Input으로 주어졌을 때, \n",
    "예시들을 참고해 차트 리뷰를 하여 환자가 {disease} 환자인지 판단합니다.\n",
    "예시들은 {imaging_report}과/와 판단입니다. \n",
    "\n",
    "예시 : {fewshot_retrieval}\n",
    "\n",
    "<판단> 에서 {disease} 환자일 확률을 0과 1사이의 값으로 나타냅니다.\n",
    "논리적으로 생각하고 <결정 근거>에서 자신의 결정에 대한 추론을 제공합니다.\n",
    "\n",
    "Output에는 다음 형식을 사용합니다.\n",
    "<판단> : (0과 1사이의 값만 해당) \n",
    "<결정근거> : \n",
    "\n",
    "Input : {input_text}\n",
    "Output :\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_completion(input_prompt, model='gpt-4-turbo-preview'):\n",
    "    client = AsyncOpenAI()\n",
    "    \n",
    "    SYSTEM_PROMPT = \"당신은 의료 AI 언어 모델입니다.\"\n",
    "    USER_PROMPT_1 = \"\"\"당신의 역할에 대해 명확합니까?\"\"\"\n",
    "    ASSISTANT_PROMPT_1 = \"\"\"네. 저는 환자를 직접 치료하지 않습니다. 하지만 의료 전문가를 도와드릴 준비가 되어있습니다. 시작하는 데 필요한 정보를 알려주세요.\"\"\"\n",
    "\n",
    "    response = await client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": USER_PROMPT_1},\n",
    "            {\"role\": \"assistant\", \"content\": ASSISTANT_PROMPT_1},\n",
    "            {\"role\": \"user\", \"content\":input_prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "        )\n",
    "    return response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def zeroshot_run_async(main_prompt, information, imaging_report, doi):\n",
    "    tasks = []\n",
    "    for i in information:\n",
    "        new_prompt = main_prompt.format(imaging_report=imaging_report, disease=doi, input_text=i)\n",
    "        tasks.append(chat_completion(new_prompt))\n",
    "    responses = await asyncio.gather(*tasks)\n",
    "    return responses\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_prob(a_value):\n",
    "    pattern = r'\\d+(\\.\\d+)?'  \n",
    "    match = re.search(pattern, str(a_value))\n",
    "\n",
    "    if match:\n",
    "        return float(match.group())\n",
    "    elif 'Output: ' in a_value:\n",
    "        try:\n",
    "            return float(a_value.split('Output: ')[1])\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "    else:\n",
    "        try:\n",
    "            return float(a_value)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "        \n",
    "        \n",
    "def calculate_entropy(p):\n",
    "    p = np.clip(p, 1e-15, 1 - 1e-15)  # prevent log(0) \n",
    "    return - (p * np.log(p) + (1 - p) * np.log(1 - p))   #binary cross entropy  \n",
    "\n",
    "def uc_grouping(entropy_list, cutoff):\n",
    "    high_idx = []\n",
    "    low_idx = []\n",
    "    for idx, entropy in enumerate(entropy_list):\n",
    "        if entropy >= cutoff:\n",
    "            high_idx.append(idx)\n",
    "        else:\n",
    "            low_idx.append(idx)\n",
    "            \n",
    "    return high_idx, low_idx      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataframe columns for each imaging type.\n",
    "for imaging_type, base_column_name in imaging_types:\n",
    "    for i in range(1, 4):  # Process each report three times\n",
    "        df[f'Stage1_{base_column_name}_predict_{i}'] = np.nan\n",
    "\n",
    "# Loop over each imaging type and count to process each three times.\n",
    "for imaging_type, base_column_name in imaging_types:\n",
    "    for i in range(1, 4):   # 3 times repeat\n",
    "        # print(f\"Processing {imaging_type}, Round {i}\")\n",
    "        \n",
    "        # Get indices and values of non-NaN entries.\n",
    "        non_nan_indices = df[imaging_type].dropna().index\n",
    "        non_nan_values = df[imaging_type].dropna().values\n",
    "                \n",
    "        # Split the data into batches of 15.\n",
    "        batches = [non_nan_values[j:j + 15].tolist() for j in range(0, len(non_nan_values), 15)]\n",
    "        \n",
    "        outputs = []\n",
    "        for batch in tqdm(batches):\n",
    "            output = await zeroshot_run_async(zeroshot_prompt, batch, imaging_type, doi)\n",
    "            outputs.extend(output)\n",
    "        \n",
    "        # Extract results from the output\n",
    "        results = [output.choices[0].message.content for output in outputs]\n",
    "        \n",
    "        # Store results in the corresponding column.\n",
    "        result_column = f'Stage1_{base_column_name}_predict_{i}'\n",
    "        for idx, result in zip(non_nan_indices, results):\n",
    "            df.at[idx, result_column] = result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary dictionary to store intermediate results for averaging later\n",
    "temp_results = {f'Stage1_{t[1]}_prob': [] for t in imaging_types}\n",
    "\n",
    "# Process each imaging type and repeat three times for each\n",
    "for imaging_type, base_column_name in imaging_types:\n",
    "    for i in range(1, 4):\n",
    "        predict_column = f'Stage1_{base_column_name}_predict_{i}'\n",
    "\n",
    "        # Get non-NaN values and their indices\n",
    "        non_nan_indices = df[predict_column].dropna().index\n",
    "        non_nan_values = df[predict_column].dropna().values\n",
    "\n",
    "        results = []\n",
    "        for value in non_nan_values:\n",
    "            results.append(detect_prob(value))\n",
    "\n",
    "        # Append results to the corresponding list in the temporary dictionary\n",
    "        temp_results[f'Stage1_{base_column_name}_prob'].append(pd.Series(results, index=non_nan_indices))\n",
    "\n",
    "# Calculate the mean probabilities for each imaging type and store them in the dataframe\n",
    "for key, value in temp_results.items():\n",
    "    if value:\n",
    "        df[key + '_mean'] = pd.concat(value, axis=1).mean(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the maximum of the mean probabilities across all imaging types and store it in the dataframe\n",
    "df['Stage1_prob'] = df[[f'Stage1_{t[1]}_prob_mean' for t in imaging_types]].max(axis=1, skipna=True)\n",
    "df['Stage1_prob'].fillna(0, inplace=True)\n",
    "\n",
    "probs = df['Stage1_prob'].values\n",
    "entropies = calculate_entropy(probs)\n",
    "df['Stage1_entropy'] = entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stage1_entropy_list = df['Stage1_entropy'].values\n",
    "cutoff_value = df['Stage1_entropy'].median()\n",
    "high, low = uc_grouping(Stage1_entropy_list, cutoff=cutoff_value)\n",
    "Stage1_high = df.loc[high].reset_index(drop=True)\n",
    "Stage1_low = df.loc[low].reset_index(drop=True)\n",
    "\n",
    "Stage1_high.to_excel('Stage1_high_entropygroup.xlsx', index=False)   # Results for the high entropy group in Stage 1\n",
    "Stage1_low.to_excel('Stage1_low_entropygroup.xlsx', index=False)    # Results for the low entropy group in Stage 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('Stage1_result.xlsx', index=False)            # Results adopted from Stage 1 only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAGE 2 : Few-Shot + RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to extract and new column names\n",
    "RAG_datasets = {\n",
    "    'MRI': ('MRI 판독문', 'Stage1_MRI_prob_mean'),\n",
    "    'CT': ('CT 판독문', 'Stage1_CT_prob_mean'),\n",
    "    'ANG': ('Cerebral Angiography 판독문', 'Stage1_ANG_prob_mean')\n",
    "}\n",
    "\n",
    "# rename to format\n",
    "for key, (input_col, output_col) in RAG_datasets.items():\n",
    "\n",
    "    data = Stage1_low[[input_col, output_col]].dropna()\n",
    "    data.rename(columns={input_col: 'Input', output_col: 'Output'}, inplace=True)\n",
    "    \n",
    "    data.to_csv(f'{key}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_retrieval_system(imaging_type):\n",
    "    ##### 1) Load documents \n",
    "    loader = CSVLoader(f'{imaging_type}.csv', source_column='Output')   \n",
    "    docs = loader.load()\n",
    "    doc_list = [doc.page_content for doc in docs]      # List comprehension to create a list for lexical search usage\n",
    "\n",
    "    ##### 2) Chunking\n",
    "    # text_splitter = RecursiveCharacterTextSplitter(\n",
    "        # chunk_size=400,  \n",
    "        # chunk_overlap=10,   \n",
    "        # separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "        # )\n",
    "\n",
    "    ##### 3) Embedding\n",
    "    model_name = 'text-embedding-ada-002' \n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=model_name,\n",
    "        openai_api_key=openai_api_key\n",
    "    )\n",
    "\n",
    "    ##### 4) Generate VectorStore\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "    ##### 5) Retrieval\n",
    "    k = 6  # Number of top similar documents to retrieve\n",
    "\n",
    "    # Lexical search setup using BM25\n",
    "    bm25_retriever = BM25Retriever.from_texts(doc_list)\n",
    "    bm25_retriever.k = k\n",
    "\n",
    "    # Semantic search setup using FAISS (cosine similarity)\n",
    "    faiss_retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",  \n",
    "        search_kwargs={'k': k}\n",
    "    )\n",
    "\n",
    "    # Hybrid search setup using a weighted combination of BM25 and FAISS\n",
    "    ensemble_retriever = EnsembleRetriever(\n",
    "        retrievers=[bm25_retriever, faiss_retriever], weights=[0.6, 0.4]\n",
    "    )\n",
    "\n",
    "    return ensemble_retriever, k\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_shots(query, retriever, k):\n",
    "    # Retrieve documents relevant to the query\n",
    "    shots_tot = retriever.get_relevant_documents(query)\n",
    "    # Extract and format the content from retrieved documents\n",
    "    shots = [doc.page_content for doc in shots_tot[:k]]\n",
    "    formatted_shots = '\\n'.join(f'{shot.split(\"Output: \")[0].strip()}\\nOutput: {shot.split(\"Output: \")[1].strip()}' for shot in shots)\n",
    "    return formatted_shots\n",
    "\n",
    "\n",
    "async def fewshot_run_async(main_prompt, information, imaging_report, doi, retriever, k):\n",
    "    tasks = []\n",
    "    for i in information:\n",
    "        shots = retrieve_shots(i, retriever, k)\n",
    "        new_prompt = main_prompt.format(imaging_report=imaging_report, disease=doi, fewshot_retrieval=shots, input_text=i)\n",
    "        # print(new_prompt)\n",
    "        tasks.append(chat_completion(new_prompt))\n",
    "    responses = await asyncio.gather(*tasks)\n",
    "    return responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imaging_type, base_column_name in imaging_types:\n",
    "    retriever, k = setup_retrieval_system(base_column_name)\n",
    "        \n",
    "    # Get indices and values of non-NaN entries.\n",
    "    non_nan_indices = Stage1_high[imaging_type].dropna().index\n",
    "    non_nan_values = Stage1_high[imaging_type].dropna().values\n",
    "                \n",
    "    # Split the data into batches of 15.\n",
    "    batches = [non_nan_values[j:j + 15].tolist() for j in range(0, len(non_nan_values), 15)]\n",
    "        \n",
    "    outputs = []\n",
    "    for batch in tqdm(batches):\n",
    "        output = await fewshot_run_async(fewshot_prompt, batch, imaging_type, doi, retriever, k)\n",
    "        outputs.extend(output)\n",
    "        \n",
    "    # Extract results from the output\n",
    "    results = [output.choices[0].message.content for output in outputs]\n",
    "        \n",
    "    # Store results in the corresponding column.\n",
    "    result_column = f'Stage2_{base_column_name}_predict'\n",
    "    for idx, result in zip(non_nan_indices, results):\n",
    "        Stage1_high.at[idx, result_column] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary dictionary to store intermediate results for averaging later\n",
    "temp_results = {f'Stage2_{t[1]}_prob': [] for t in imaging_types}\n",
    "\n",
    "# Process each imaging type and repeat three times for each\n",
    "for imaging_type, base_column_name in imaging_types:\n",
    "    predict_column = f'Stage2_{base_column_name}_predict'\n",
    "\n",
    "    # Get non-NaN values and their indices\n",
    "    non_nan_indices = Stage1_high[predict_column].dropna().index\n",
    "    non_nan_values = Stage1_high[predict_column].dropna().values\n",
    "\n",
    "    results = []\n",
    "    for value in non_nan_values:\n",
    "        results.append(detect_prob(value))\n",
    "\n",
    "    # Append results to the corresponding list in the temporary dictionary\n",
    "    temp_results[f'Stage2_{base_column_name}_prob'].append(pd.Series(results, index=non_nan_indices))\n",
    "\n",
    "# Calculate the mean probabilities for each imaging type and store them in the dataframe\n",
    "for key, value in temp_results.items():\n",
    "    if value:\n",
    "        Stage1_high[key + '_mean'] = pd.concat(value, axis=1).mean(axis=1, skipna=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the maximum of the mean probabilities across all imaging types and store it in the dataframe\n",
    "Stage1_high['Stage2_prob'] = Stage1_high[[f'Stage2_{t[1]}_prob_mean' for t in imaging_types]].max(axis=1, skipna=True)\n",
    "Stage1_high['Stage2_prob'].fillna(0, inplace=True)\n",
    "\n",
    "probs = Stage1_high['Stage2_prob'].values\n",
    "entropies = calculate_entropy(probs)\n",
    "Stage1_high['Stage2_entropy'] = entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stage2_entropy_list = Stage1_high['Stage2_entropy'].values\n",
    "cutoff_value = Stage1_high['Stage2_entropy'].median()\n",
    "high, low = uc_grouping(Stage2_entropy_list, cutoff=cutoff_value)\n",
    "Stage2_high = Stage1_high.loc[high].reset_index(drop=True)    \n",
    "Stage2_low = Stage1_high.loc[low].reset_index(drop=True)\n",
    "\n",
    "Stage2_high.to_excel('Stage2_high_entropygroup.xlsx', index=False)   # Results for the high entropy group in Stage 2\n",
    "Stage2_low.to_excel('Stage2_low_entropygroup.xlsx', index=False)    # Results for the low entropy group in Stage 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stage1_low['Stage2_prob'] = Stage1_low['Stage1_prob']\n",
    "combined_df_1= pd.concat([Stage1_low, Stage1_high], ignore_index=True)\n",
    "combined_df_1.to_excel('Stage2_result.xlsx', index=False)      # Results adopted from Stage 1, and Stage 2\n",
    "\n",
    "\n",
    "Stage1_low['Stage3_prob'] = Stage1_low['Stage1_prob']\n",
    "Stage2_low['Stage3_prob'] = Stage2_low['Stage2_prob']\n",
    "Stage2_high['Stage3_prob'] = Stage2_high['Label']\n",
    "combined_df_2= pd.concat([Stage1_low, Stage2_low, Stage2_high], ignore_index=True)\n",
    "combined_df_2.to_excel('Stage3_result.xlsx', index=False)      # Results adopted from Stage 1, Stage 2, and Stage 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_datasets = [\n",
    "    ('Stage1_low_entropygroup.xlsx', 'Stage1_prob'),  # Results for the low entropy group in Stage 1\n",
    "    ('Stage1_high_entropygroup.xlsx', 'Stage1_prob'),  # Results for the high entropy group in Stage 1\n",
    "    ('Stage2_low_entropygroup.xlsx', 'Stage2_prob'),  # Results for the low entropy group in Stage 2\n",
    "    ('Stage2_high_entropygroup.xlsx', 'Stage2_prob'),  # Results for the high entropy group in Stage 2\n",
    "    ('Stage1_result.xlsx', 'Stage1_prob'),  # Results adopted from only Stage 1 \n",
    "    ('Stage2_result.xlsx', 'Stage2_prob'),  # Results adopted from Stage 1, 2 \n",
    "    ('Stage3_result.xlsx', 'Stage3_prob'),  # Results adopted from Stage 1, 2, 3 \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_binary_classification(df, prob_column):\n",
    "    # Remove rows where the Label is 'equivocal' (Label == 1)\n",
    "    df = df[df['Label'] != 1]\n",
    "    # print(len(df))\n",
    "    \n",
    "    # Perform binary classification based on the probability threshold of 0.5\n",
    "    df['Predicted'] = (df[prob_column] > 0.5).astype(int)\n",
    "    df['Label'] = df['Label'].replace({0: 0, 2: 1})\n",
    "    \n",
    "    # Extract true labels and predicted labels\n",
    "    y_true = df['Label'].values\n",
    "    y_pred = df['Predicted'].values\n",
    "\n",
    "    # Calculate True Positives, False Positives, True Negatives, and False Negatives\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    # print(TP+TN+FP+FN)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0  # also known as Recall\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    PPV = TP / (TP + FP) if (TP + FP) > 0 else 0  # also known as Precision\n",
    "    NPV = TN / (TN + FN) if (TN + FN) > 0 else 0\n",
    "    f1_score = 2 * (PPV * sensitivity) / (PPV + sensitivity) if (PPV + sensitivity) > 0 else 0\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"specificity\": specificity,\n",
    "        \"PPV\": PPV,\n",
    "        \"NPV\": NPV,\n",
    "        \"f1_score\": f1_score,\n",
    "        \"kappa\": kappa\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_multiclass_classification(df, prob_column, lower_bound=0.45, upper_bound=0.55):\n",
    "    # Function to classify probabilities into multiclass categories\n",
    "    def classify_multiclass(prob):\n",
    "        if prob < lower_bound:\n",
    "            return 0  # Negative\n",
    "        elif prob > upper_bound:\n",
    "            return 2  # Positive\n",
    "        else:\n",
    "            return 1  # Equivocal\n",
    "\n",
    "    # Apply classification to each probability\n",
    "    y_prob = np.array(df[prob_column])\n",
    "    y_pred = np.array([classify_multiclass(p) for p in y_prob])\n",
    "    y_true = np.array(df['Label'])\n",
    "    \n",
    "    # Generate a classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=['Negative', 'Equivocal', 'Positive'], output_dict=False)\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the list of files and evaluate binary classification performance\n",
    "for file_name, prob_column in evaluation_datasets:\n",
    "    ev = pd.read_excel(file_name)\n",
    "    metrics = evaluate_binary_classification(ev, prob_column)\n",
    "    print(f\"Binary Classification Evaluation for {file_name}:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key}: {value:.2f}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the list of files and evaluate multiclass classification\n",
    "for file_name, prob_column in evaluation_datasets:\n",
    "    ev = pd.read_excel(file_name)\n",
    "    report = evaluate_multiclass_classification(ev, prob_column)\n",
    "    print(f\"Multiclass Classification Evaluation for {file_name}:\\n{report}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
